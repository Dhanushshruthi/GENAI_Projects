{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGy-QhvmMiKp",
        "outputId": "8c0bd458-742d-4b30-d60e-dc3743adacab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBof7hC6MG93",
        "outputId": "87c81693-cb51-40a9-eb2a-cfb7cad5dc90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Question Answering Chatbot! Type 'exit' to end the chat.\n",
            "\n",
            "Ask a question: what is RCNN?\n",
            "\n",
            "Top Answers:\n",
            "1. Answer: region based convolutional neural networks\n",
            "   Context: REGION BASED CONVOLUTIONAL NEURAL\n",
            "NETWORKS(R-CNN)\n",
            "PRESENTED BY:\n",
            "DHANUSHSHRUTHI S T CONVOLUTIONAL NEURAL NETWORKS:\n",
            "A Convolutional Neural Network (CNN) is a type of artificial neural network specifically\n",
            "designed for processing structured grid data, such as images\n",
            "2. Answer: \n",
            "   Context: FASTER R-CNN\n",
            "➢ Imagine you're playing a game where you need to find hidden objects in a large picture.\n",
            "Faster R-CNN is like having a super-fast teammate who helps you find the objects quickly\n",
            "and accurately.\n",
            "➢ Here's how it works:\n",
            "1.Scanning Quickly: Your teammate quickly scans the entire picture to spot areas where\n",
            "objects might be hidden\n",
            "\n",
            "Ask a question: what is Pooling layer?\n",
            "\n",
            "Top Answers:\n",
            "1. Answer: you ' re trying to shrink down the picture while keeping the important parts\n",
            "   Context: Each\n",
            "square represents a pixel in the image.\n",
            "In a pooling layer, you're trying to shrink down the picture while keeping the important\n",
            "parts\n",
            "2. Answer: imagine you have a big picture made up of lots of small squares\n",
            "   Context: POOLING LAYER:\n",
            "➢ Imagine you have a big picture made up of lots of small squares, like a puzzle\n",
            "\n",
            "Ask a question: what is dense layer?\n",
            "\n",
            "Top Answers:\n",
            "1. Answer: a meeting room where everyone shares their opinion\n",
            "   Context: DENSE LAYER:\n",
            "➢ Think of a dense layer like a meeting room where everyone shares their opinion, and\n",
            "then decisions are made based on those opinions.\n",
            "Each person in the room represents a neuron in the layer\n",
            "2. Answer: gathering information from every input neuron\n",
            "   Context: Finally, this sum goes through an activation function to produce the\n",
            "final decision.\n",
            "➢ So, a dense layer is essentially about gathering information from every input neuron,\n",
            "weighing that information, combining it, and making a decision based on it\n",
            "\n",
            "Ask a question: what is CNN?\n",
            "\n",
            "Top Answers:\n",
            "1. Answer: cnns are particularly effective in tasks like image recognition\n",
            "   Context: CNNs are particularly effective\n",
            "in tasks like image recognition, classification, object detection, and segmentation\n",
            "2. Answer: a convolutional neural network\n",
            "   Context: REGION BASED CONVOLUTIONAL NEURAL\n",
            "NETWORKS(R-CNN)\n",
            "PRESENTED BY:\n",
            "DHANUSHSHRUTHI S T CONVOLUTIONAL NEURAL NETWORKS:\n",
            "A Convolutional Neural Network (CNN) is a type of artificial neural network specifically\n",
            "designed for processing structured grid data, such as images\n",
            "\n",
            "Ask a question: what is ROI?\n",
            "\n",
            "Top Answers:\n",
            "1. Answer: standardizing and summarizing different - sized regions in images\n",
            "   Context: These values represent the most important features of the original regions.\n",
            "➢ So, ROI pooling is like standardizing and summarizing different-sized regions in images,\n",
            "making them easier to compare and analyze in a neural network\n",
            "2. Answer: pooling\n",
            "   Context:  ROI POOLING:\n",
            "➢ Imagine you have a bunch of different-sized photos, and you want to compare them side by\n",
            "side\n",
            "\n",
            "Ask a question: exit\n",
            "Goodbye!\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import pdfplumber\n",
        "\n",
        "# Step 1: Extract corpus from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() + \" \"\n",
        "    return text.strip()\n",
        "\n",
        "# Step 2: Dense Retriever using Sentence Transformers\n",
        "retriever_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "# Load the PDF and process the content\n",
        "pdf_path = \"/content/drive/MyDrive/R-CNN PPT.pdf\"  # Replace with your PDF file path\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "corpus = pdf_text.split(\". \")  # Split into smaller passages (adjust if necessary)\n",
        "\n",
        "# Step 3: Generate embeddings for the corpus\n",
        "corpus_embeddings = retriever_model.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Step 4: Define a function to retrieve relevant passages\n",
        "def retrieve_passages(question, top_k=2):\n",
        "    question_embedding = retriever_model.encode(question, convert_to_tensor=True)\n",
        "    scores = util.cos_sim(question_embedding, corpus_embeddings)\n",
        "    top_results = torch.topk(scores, k=top_k, dim=1)\n",
        "\n",
        "    top_indices = top_results.indices[0].tolist()\n",
        "    retrieved_passages = [corpus[idx] for idx in top_indices]\n",
        "    return retrieved_passages\n",
        "\n",
        "# Step 5: BERT Reader for Question Answering\n",
        "qa_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(qa_model_name)\n",
        "qa_model = AutoModelForQuestionAnswering.from_pretrained(qa_model_name)\n",
        "\n",
        "# Define a function to get answers\n",
        "def get_answer(question, passage):\n",
        "    inputs = tokenizer(question, passage, return_tensors=\"pt\", truncation=True)\n",
        "    outputs = qa_model(**inputs)\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "\n",
        "    start_idx = torch.argmax(start_scores)\n",
        "    end_idx = torch.argmax(end_scores) + 1\n",
        "\n",
        "    answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# Step 6: Integrate Retrieval + Reader\n",
        "def question_answering_system(question):\n",
        "    # Step 6.1: Retrieve relevant passages\n",
        "    retrieved_passages = retrieve_passages(question)\n",
        "\n",
        "    # Step 6.2: Use BERT to extract answers\n",
        "    answers = []\n",
        "    for passage in retrieved_passages:\n",
        "        answer = get_answer(question, passage)\n",
        "        answers.append((answer, passage))\n",
        "\n",
        "    return answers\n",
        "\n",
        "# Chatbot Loop\n",
        "print(\"Welcome to the Question Answering Chatbot! Type 'exit' to end the chat.\")\n",
        "while True:\n",
        "    question = input(\"\\nAsk a question: \")\n",
        "    if question.lower() == 'exit':\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    answers = question_answering_system(question)\n",
        "    print(\"\\nTop Answers:\")\n",
        "    for idx, (answer, passage) in enumerate(answers):\n",
        "        print(f\"{idx+1}. Answer: {answer}\")\n",
        "        print(f\"   Context: {passage}\")\n"
      ]
    }
  ]
}