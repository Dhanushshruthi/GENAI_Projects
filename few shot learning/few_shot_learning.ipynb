{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6npkkS2m-b_9",
        "outputId": "030e24b5-5d0f-499a-e76d-b4e245744703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision matplotlib pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Siamese Network Definition\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128 * 32 * 32, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Contrastive Loss Function\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
        "        loss = torch.mean(\n",
        "            (1 - label) * torch.pow(euclidean_distance, 2) +\n",
        "            (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "# Dataset for Image Pairs\n",
        "class ImagePairDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = os.listdir(root_dir)\n",
        "        self.image_paths = {cls: [os.path.join(root_dir, cls, img) for img in os.listdir(os.path.join(root_dir, cls))]\n",
        "                            for cls in self.classes}\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        class1 = random.choice(self.classes)\n",
        "        img1_path = random.choice(self.image_paths[class1])\n",
        "        img1 = Image.open(img1_path).convert(\"RGB\")\n",
        "\n",
        "        should_get_same_class = random.randint(0, 1)\n",
        "        if should_get_same_class:\n",
        "            img2_path = random.choice(self.image_paths[class1])\n",
        "            label = 1\n",
        "        else:\n",
        "            class2 = random.choice([cls for cls in self.classes if cls != class1])\n",
        "            img2_path = random.choice(self.image_paths[class2])\n",
        "            label = 0\n",
        "\n",
        "        img2 = Image.open(img2_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "\n",
        "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum(len(imgs) for imgs in self.image_paths.values())\n",
        "\n",
        "# Training Function\n",
        "def train_model(dataset_path, epochs=5, batch_size=32, learning_rate=0.001):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    dataset = ImagePairDataset(root_dir=dataset_path, transform=transform)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = SiameseNetwork().to(device)\n",
        "    criterion = ContrastiveLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for img1, img2, label in data_loader:\n",
        "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output1 = model(img1)\n",
        "            output2 = model(img2)\n",
        "            loss = criterion(output1, output2, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(data_loader):.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Testing Function with Class Name Display\n",
        "def test_model(model, img1_path, img2_path, class_names):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Load images and their class names\n",
        "    img1 = Image.open(img1_path).convert(\"RGB\")\n",
        "    img2 = Image.open(img2_path).convert(\"RGB\")\n",
        "\n",
        "    img1_class = img1_path.split(\"/\")[-2]\n",
        "    img2_class = img2_path.split(\"/\")[-2]\n",
        "\n",
        "    img1 = transform(img1).unsqueeze(0).to(device)\n",
        "    img2 = transform(img2).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output1 = model(img1)\n",
        "        output2 = model(img2)\n",
        "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
        "\n",
        "    print(f\"Class of Image 1: {img1_class}\")\n",
        "    print(f\"Class of Image 2: {img2_class}\")\n",
        "    print(f\"Euclidean Distance: {euclidean_distance.item():.4f}\")\n",
        "\n",
        "    threshold = 0.5  # Set the threshold based on testing (experiment with this value)\n",
        "    if euclidean_distance.item() < threshold:\n",
        "        print(\"The images are likely from the same class.\")\n",
        "    else:\n",
        "        print(\"The images are likely from different classes.\")\n",
        "\n",
        "# Usage Example\n",
        "# Training\n",
        "trained_model = train_model(\n",
        "    dataset_path=\"/content/drive/MyDrive/few shot learning\",\n",
        "    epochs=20,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Testing\n",
        "test_model(\n",
        "    model=trained_model,\n",
        "    img1_path=\"/content/drive/MyDrive/few shot learning/cat/cat 10.jpeg\",\n",
        "    img2_path=\"/content/drive/MyDrive/few shot learning/dog/img 27.jpeg\",\n",
        "    class_names=[\"cat\", \"dog\"]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFnbfcDb-mWd",
        "outputId": "e3efa041-9a9e-475f-f91d-2e0981926fb4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 122.6227\n",
            "Epoch [2/20], Loss: 11.4142\n",
            "Epoch [3/20], Loss: 3.0808\n",
            "Epoch [4/20], Loss: 1.3770\n",
            "Epoch [5/20], Loss: 1.1474\n",
            "Epoch [6/20], Loss: 1.6036\n",
            "Epoch [7/20], Loss: 1.4107\n",
            "Epoch [8/20], Loss: 1.5781\n",
            "Epoch [9/20], Loss: 1.5887\n",
            "Epoch [10/20], Loss: 1.1281\n",
            "Epoch [11/20], Loss: 1.2526\n",
            "Epoch [12/20], Loss: 1.3610\n",
            "Epoch [13/20], Loss: 1.2847\n",
            "Epoch [14/20], Loss: 1.5405\n",
            "Epoch [15/20], Loss: 1.4908\n",
            "Epoch [16/20], Loss: 1.4924\n",
            "Epoch [17/20], Loss: 1.8065\n",
            "Epoch [18/20], Loss: 1.5692\n",
            "Epoch [19/20], Loss: 1.8273\n",
            "Epoch [20/20], Loss: 1.6245\n",
            "Class of Image 1: cat\n",
            "Class of Image 2: dog\n",
            "Euclidean Distance: 1.1389\n",
            "The images are likely from different classes.\n"
          ]
        }
      ]
    }
  ]
}